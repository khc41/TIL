## 📅 2025-06-09
### 📚 읽은 개발 서적: [가상면접 사례로 배우는 대규모 시스템 설계 기초](https://product.kyobobook.co.kr/detail/S000001033116)
#### ✏️ 4장 - 처리율 제한 장치의 설계
- 처리율 제한 장치란 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제한하기 위한 장치로 DoS 공격에 의한 자원 고갈을 방지, 비용 절감, 서버 과부하 방지 등의 이점이 있다.
#### 1단계: 문제 이해 및 설계 범위 확정
- 종류 (클라이언트 / 서버), 제어 규칙 (IP / ID), 시스템 규모, 환경 (분산 환경), 독립성 (소스 코드내 / 서비스), 제한 여부 통지 등을 면접관과 대화하면서 요구사항을 정리한다.
- 요구사항
  - 설정된 처리율 초과하는 요청은 정확하게 제한한다.
  - 낮은 응답시간을 유지한다.
  - 가능한 적은 메모리를 써야 한다.
  - 하나의 처리율 제한 장치를 여러 서버나 프로세스에서 공유할 수 있어야 한다.
  - 요청이 제한되었을 때, 사용자에게 분명히 알려줘야 한다.
  - 장애가 생기더라도 전체 시스템에 영향을 주어선 안된다.
#### 2단계: 개략적 설계안 제시 및 동의 구하기
- 처리율 제한 장치의 위치 
    - 클라이언트, 서버, 미들웨어 
    - 현재 기술 스택이나 엔지니어링 인력, 우선순위, 목표에 따라 달라질 수 있다.
      - 현재 사용하는 언어가 서버 측 구현을 지원하기 출분할 정도로 효율이 높은지 확인해라.
      - 사업 필요에 맞는 알고리즘을 찾아라.
      - 마이크로 서비스에 기반하고 있고, API 게이트웨이를 이미 설계에 포함시켰다면 처리율 제한 기능 또한 게이트웨이에 포함시켜야 할 수도 있다.
      - 구현하기 충분한 인력이 없다면 상용 API 게이트웨이를 써라
- 처리율 제한 알고리즘
  - 토큰 버킷 알고리즘
    - 폭넓게 이용되고 보편적으로 사용하고 있다.
    - 알고리즘 설명
      - 토큰 버킷은 지정된 용량을 가진 컨테이너로 이 버킷에는 사전 설정된 양의 토큰이 주기적으로 채워진다. 토큰이 꽉 찬 버킷에는 토큰이 추가되지 않는다.
      - 각 요청이 처리될 때마다 하나의 토큰을 사용한다. 충분한 토큰이 없는 경우, 해당 요청은 버려진다.
      - 버킷 크기와 토큰 공급률의 두 가지 인자를 받아 처리율을 조절한다.
      - 통상적으로 API 엔드포인트마다 별도의 버킷을 둔다.
      - IP 주소별로 처리율 제한을 적용해야 한다면 IP 주소마다 버킷을 하나씩 할당해야 한다.
    - 장점
      - 구현이 쉽고 메모리 효율적이다. 짧은 시간 집중되는 트래픽도 처리 가능하다.
    - 단점
      - 버킷 크기와 토큰 공급률을 적절히 튜닝하는게 까다롭다.
  - 누출 버킷 알고리즘
    - 토큰 버킷 알고리즘과 비슷하지만 요청 처리율이 고정되어 있다는 점이 다르다.
    - FIFO 큐로 구현한다.
    - 버킷 크기와 처리율을 인자로 가지고 있다.
    - 알고리즘 설명
      - 요청이 도착하면 큐가 가득 차 있는지 확인하고 빈자리가 있는 경우 큐에 요청을 추가한다.
      - 큐가 가득 차 있으면 새 요청을 버린다.
      - 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.
    - 장점
      - 메모리 효율적이고, 고정된 처리율을 갖고 있어서 안정적 출력이 필요한 경우 적합하다.
    - 단점
      - 단시간에 많은 트래픽이 몰리는 경우 최신 요청들은 버려지게 된다.
      - 버킷 크기와 처리율을 튜닝하기 까다롭다.
  - 고정 윈도 카운터 알고리즘
    - 알고리즘 설명
      - 타임라인을 고정된 윈도로 나누고 각 윈도마다 카운터를 붙인다.
      - 요청이 접수될 때마다 카운터 값은 1씩 증가한다.
      - 카운터 값이 임계치에 도달하면 새로운 요청은 새 윈도가 열릴 때까지 버려진다.
    - 장점
      - 메모리 효율이 좋고 이해하기 쉽고 윈도가 닫히는 시점에 카운터를 초기화하는 방식으로 특정한 트래픽 패턴을 처리하기 적합하다.
    - 단점
      - 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 시스템 처리 한도보다 많은 양의 요청을 처리하게 된다.
  - 이동 윈도 로깅 알고리즘
    - 알고리즘 설명
      - 요청의 타임스탬프를 추척하는데 이 데이터는 보통 레디스의 sorted set 같은 캐시에 보관한다.
      - 새 요청이 오면 만료된 타임스탬프를 제거한다.
      - 새 요청의 타임스탬프를 로그에 추가한다.
      - 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다.
    - 장점
      - 처리율 제한 메커니즘이 정교하다.
    - 단점
      - 다량의 메모리를 사용한다.
  - 이동 윈도 카운터 알고리즘
    - 현재 시간대의 요청 수 + 직전 시간대의 요청 수 * 이동 윈도와 직전 윈도가 겹치는 비율로 계산한다.
    - 장점
      - 짧은 시간에 몰리는 트래픽에 잘 대응하고 메모리 효율이 좋다.
    - 단점
      - 직전 시간대 요청이 균등하다고 가정하고 추정치를 계산하기 때문에 다소 느슨하다.
- 개략적인 아키텍처
  - Redis는 빠르고 시간에 기반한 만료 정책을 지원하기 때문에 쉽게 구현할 수 있다.
  - 미들웨어에서 레디스의 지정 버킷에서 카운터를 가져와 한도에 도달했는지 체크하고 카운터의 값을 관리한다. 
- 상세 설계
  - 처리율 한도 초과 트래픽 처리
    - 처리율 제한 규칙들은 보통 설정 파일 형태로 디스크에 저장된다.
    - 어떤 요청이 한도 제한에 걸리면 HTTP 429 응답을 보내거나 경우에 따라서는 나중에 처리하기 위해 큐에 보관할 수도 있다.
    - HTTP 헤더를 통해 제한과 관련된 정보를 클라이언트에게 전달할 수 있다.
  - 분산 환경에서 처리율 제한 장치 구현
    - 경쟁 조건
      - redis에서 counter를 가져와 1을 더하고 저장하는 과정에서 경쟁 조건이슈가 발생할 수 있다.
      - Lock은 시스템 성능을 상당히 떨어뜨린다는 문제가 있다.
      - 대신에 루아 스크립트를 이용하거나 Sorted Set을 이용해 해결할 수 있다.
    - 동기화 이슈
      - 처리율 제한 장치 서버가 여러대면 동기화가 필요해진다.
      - Redis를 사용해 중앙 저장소로 사용하면 해결할 수 있다.
    - 성능 최적화
      - 사용자 트래픽을 가장 가까운 엣지 서버로 전달해 지연 시간을 줄인다.
      - 데이터 동기화할 때 최종 일관성 모델을 사용해라
    - 모니터링
      - 처리율 제한 알고리즘이 효과적인지, 정의한 처리율 제한 규칙이 효과적인지 모니터링 해야한다.
  - 마무리
    - 경성, 연성 처리율 제한
      - 경성은 임계치를 절대 넘어설 수 없고, 연성은 잠시 동안 임계치를 넘어설 수 있다.
    - 다양한 계층에서 처리율 제한
      - 애플리케이션 계층이 아닌 다른 계층에서도 처리율 제한이 가능하다.
    - 처리율 제한을 회피하는 방법
      - 클라이언트 캐시 사용
      - 재시도 로직을 구현할 때는 충분한 백오프 시간을 둔다.

#### 💡 느낀 점
- 처리율 제한 장치를 설계하는 과정에서 정답은 없고 현재 기술 스택이나 인력, 우선순위, 목표에 따라 달라질 수 있다는 말이 인상깊었다.
- 다양한 알고리즘들을 배웠고, 각 알고리즘의 장단점과 어떤 상황에서 사용하는지에 대해 알 수 있었다.
- 본격적인 설계를 들어가는 구간에서 설계를 어떻게 해야하는지, 어떤 부분을 고려해야 하는지 배울 수 있었다.