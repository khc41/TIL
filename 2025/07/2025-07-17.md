## 📅 2025-07-17
### 📚 읽은 개발 서적: [가상면접 사례로 배우는 대규모 시스템 설계 기초](https://product.kyobobook.co.kr/detail/S000001033116)
#### ✏️ 13장 - 검색어 자동완성 시스템
#### 1단계 - 문제 이해 및 설계 범위 확정
- 입력하는 단어가 자동완성될 검색어의 첫 부분인지 아니면 중간 부분인지 확인한다.
- 자동완성 검색어의 개수, 고르는 기준, 맞춤법 검사 기능 제공 여부, 질의 언어, 대문자나 특수문자 처리, 트래픽 규모 등을 논의해 요구사항을 확정한다.
- **개략 요구사항**
  - 빠른 응답 속도: 100ms 이내 (페이스북 참고)
  - 연관성 높은 검색어 제공
  - 인기도 등의 순위 모델에 의한 정렬
  - 규모 확장성 고려
  - 고가용성 보장
- **개략적 규모 추정**
  - 일간 능동 사용자는 천만명으로 가정
  - 평균적으로 한 사용자는 매일 10건의 검색 수행
  - 질의할 때마다 평균 20바이트 데이터 입력 (ASCII 기준 평균 4개 단어, 각 단어는 5글자로 가정)
  - 글자를 입력할 때마다 검색어 자동완성 백엔드에 요청 (1회 검색당 20건 요청)
  - 초당 24,000건 질의(QPS) 발생 (10,000,000 * 10 / 1 * 20 / 24 / 3600)
  - 최대 QPS = QPS * 2 = 48,000
  - 질의 가운데 20% 정도는 신규 검색어라고 가정할 때 매일 0.4GB(=10,000,000 * 10 / 1 * 20 * 20%) 데이터 신규 추가
#### 2단계 - 개략적 설계안 제시 및 동의 구하기
- **데이터 수집 서비스**
  - 질의문과 사용빈도를 저장하는 빈도 테이블이 있다고 가정
- **질의 서비스**
  - 같은 빈도 테이블이 있다고 가정, 사용자가 검색창에 입력하면 top5 자동완성 검색어를 정렬해서 반환
  - 데이터가 아주 많아지면 데이터베이스에 병목 발생 가능
#### 3단계 - 상세 설계
- **트라이 자료구조**
  - 트라이는 트리 형태의 자료구조로, 각 노드는 글자 하나를 저장하며, 26개의 자식 노드를 가질 수 있다.
  - 이용 빈도에 따라 정렬된 결과를 내놓기 위해 노드에 빈도 정보까지 저장해야 한다.
  - 가장 많이 사용된 질의어 k개를 찾는 방법 (p: 접두어의 길이, n: 트라이 안에 있는 노드 개수, c: 주어진 노드의 자식 노드 개수)
    - 해당 접두어를 표현하는 노드를 찾는다 O(p)
    - 해당 노드부터 시작하는 하위 트리를 탐색해 모든 유효 노드를 찾는다. O(c)
    - 유효 노드들을 정렬하여 가장 인기 있는 검색어 k개를 찾는다. O(c * log(c))
    - 최악의 경우 k개 결과를 얻으려고 전체 트라이를 다 검색해야 하는 일이 생길 수 있음
  - **접두어 최대 길이 제한**
    - 검색창에 긴 검색어를 입력하는 일은 거의 없으므로 최대 길이를 제한할 수 있다면 O(p)에서 O(1)로 줄일 수 있다.
  - **노드에 인기 검색어 캐시**
    - 각 노드에 k개의 인기 검색어를 저장해 두면 전체 트라이를 검색하는 일을 방지할 수 있다.
    - 하지만, 각 노드에 질의어를 저장할 공간이 많이 필요하게 된다.
  - 두 가지 방법을 조합하면 O(1) + O(1) 이므로 시간 복잡도를 O(1)로 줄일 수 있다.
- **데이터 수집 서비스**
  - 매일 수천만 건의 질의마다 트라이를 갱신하면 질의 서비스는 심각하게 느려진다.
  - 인기 검색어는 자주 바뀌지 않을 것이고, 자주 갱신할 필요 없다.
  - 트위터 같은 실시간 서비스는 검색어를 신선하게 유지해야 하지만, 구글 검색 같은 애플리케이션은 자주 바꿀 필요 없다.
> 데이터 분석 서비스 로그 -> 로그 취합 서버 -> 취합된 데이터 -> 작업 서버 -> (매주 갱신) 트라이 데이터베이스 -> (매주 데이터베이스 상태를 스냅샷) 트라이 캐시
  - **데이터 분석 서비스 로그**
    - 검색창에 입력된 질의에 관한 원본 데이터 보관
    - 인덱스 X
  - **로그 취합 서버**
    - 로그는 양이 엄청나고 데이터 형식도 제각각이므로 잘 취합해 시스템이 쉽게 소비할 수 있도록 해야한다.
    - 실시간 서비스는 데이터 취합주기를 빠르게 가져간다.
  - **취합된 데이터**
    - query, time, frequency 로 구성된 데이터, 해당 질의가 해당 주에 사용된 횟수의 합
  - **작업 서버**
    - 비동기적으로 작업 수행
    - 트라이 자료구조를 만들고 트라이 데이터베이스에 저장
  - **트라이 캐시**
    - 트라이 데이터를 메모리에 유지하여 읽기 연산 성능을 높임, 스냅샷 떠서 갱신
  - **트라이 데이터베이스**
    - 문서 저장소
      - 주기적으로 트라이를 직렬화하여 데이터베이스에 저장
    - 키-값 저장소
      - 트라이에 보관된 모든 접두어를 해시 테이블 키로 변환한 후, 각 트라이 노드에 보관된 모든 데이터를 해시 테이블 값으로 변환
- **질의 서비스**
  - 로드밸런서를 통해 API 서버에 온 요청을 통해 트라이 캐시에 접근한 뒤, 없으면 트라이 데이터베이스에서 가져온다.
  - 최적화 방안
    - AJAX 요청: 요청을 보내고 받기 위해 페이지 새로고침 필요가 없다.
    - 브라우저 캐싱: 검색어 제안 결과는 짧은 시간안에 자주 바뀌지 않으므로 브라우저 캐시에 넣어두면 후속 질의의 결과는 해당 캐시에서 바로 가져갈 수 있다.
    - 데이터 샘플링: 모든 질의 결과를 로깅하면 CPU 자원과 저장공간을 엄청나게 소진하므로, N개 요청 가운데 1개만 로깅하도록 한다.
- **트라이 연산**
  - 트라이 생성
    - 작업 서버가 담당하며, 취합된 데이터를 이용한다.
  - 트라이 갱신
    1. 매주 한 번 새로운 트라이를 만든 다음 기존 트라이를 대체한다.
    2. 트라이의 각 노드를 개별적으로 갱신하는 방법 (성능이 좋지 않아 트라이가 작을 때 고려해볼만 하다.)
  - 검색어 삭제
    - 혐오성이 짙거나, 폭력적이거나, 성적으로 노골적이거나 위험한 질의어는 제거해야 한다.
    - 트라이 캐시 앞에 필터 계층을 두고 부적절한 질의어가 반환되지 않도록 한다.
- **저장소 규모 확장**
  - 트라이의 크기가 한 서버에 넣기엔 너무 큰 경우에도 대응
  - 영어만 지원하면 되기 때문에 첫 글자를 기준으로 샤딩하는 방법
  - 최대 26개의 서버 지원 (알파벳 개수)
  - 'c'로 시작하는 단어가 'x'로 시작하는 단어보다 많기 때문에 데이터를 각 서버에 균등하게 배분하기 불가능
    - 과거 질의 데이터의 패턴을 분석해 샤딩하는 방법 지원, 예를 들어 's'로 시작하는 검색어의 양이 'u', 'v', 'w'를 합친 것과 비슷하다면, 샤드 두 개로 나눠서 저장
#### 4단계 - 마무리
- **추가 논의 사항**
  - 다국어 지원 (unicode 사용)
  - 국가별로 인기 검색어 순위가 다른 경우 (국가별 다른 트라이 사용, CDN에 저장)
  - 실시간으로 변하는 검색어 추이 반영
    - 샤딩을 통해 작업 대상 데이터의 양을 줄인다.
    - 순위 모델을 바꾸어 최근 검색어에 높은 가중치를 준다.
    - 데이터가 스트림 형태로 올 수 있다는 점을 고려한다. 하둡 맵리듀스, 스파크 스트리밍, 스톰, 카프카 등을 사용한다.
#### 💡 느낀 점
- 애플리케이션의 실시간성에 따라 트라이 자료구조를 어떤 주기로 갱신할 지 결정해야 한다는 점이 인상 깊었다.
- 중간 부분에서 작업서버간에 작업한 트라이를 어떻게 저장된 트라이랑 합칠까 궁금했었는데, 데이터 주기와 요구사항을 분석해 주 단위로 대체하는 것을 보고 효율적인 방법이라고 생각했다.
- 트라이를 샤딩할 때 Hot Key 문제를 어떻게 해결하는지 궁금했는데, 과거의 데이터 패턴을 분석해 샤딩하는 방법이 참신하다고 생각했다.