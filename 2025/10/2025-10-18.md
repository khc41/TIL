### 📚 읽은 개발 서적: [데이터 중심 애플리케이션 설계](https://www.yes24.com/Product/Goods/59566585?pid=123487&cosemkid=go16406746660905354&utm_source=google_pc&utm_medium=cpc&utm_campaign=book_pc&utm_content=ys_240530_google_pc_cc_book_pc_12110%EB%8F%84%EC%84%9C2&utm_term=%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A4%91%EC%8B%AC%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98%EC%84%A4%EA%B3%84&gad_source=1&gad_campaignid=6762605740&gbraid=0AAAAAD79Irrfvaqb4HDi15JUqflihSilR&gclid=Cj0KCQjw3aLHBhDTARIsAIRij5-GpSKsMKO8XIATcjMBStXbk-93KGuGTmn0kK3NAbsbDtX417fNAIUaAih4EALw_wcB)
#### 3장. 저장소와 검색
##### 데이터베이스를 강력하게 만드는 데이터 구조
~~~bash
#!/bin/bash

db_set() {
  echo "$1,$2" >> database
}

db_get() {
    grep "^$1, " database | sed -e "s/^$1,//" | tail -n 1
}
~~~
- 매 라인마다 쉼표로 구분된 키-값 쌍을 포함한 텍스트 파일형식으로 구현한 세상에서 제일 간단한 키-값 저장소이다.
- 쓰기 작업
  - db_set을 호출할 때마다 파일의 끝에 추가하므로 키를 여러 번 갱신해도 값의 예전 버전을 덮어 쓰지 않는다.
  - 파일 추가 작업은 매우 효율적이기에 좋은 성능을 보여주고 많은 데이터베이스는 내부적으로 추자 전용 (append-only) 데이터 파일인 로그를 사용한다.
- 읽기 작업
  - 최신 값을 찾기 위해서는 파일에서 키의 마지막 항목을 살펴봐야 한다.
  - 키가 있는지 찾기 위해 데이터베이스 파일을 처음부터 끝까지 스캔해야하기 때문에 검색 비용이 O(N)이고, 많은 레코드가 있으면 성능이 매우 좋지 않다.
  - 특정 키의 값을 효율적으로 찾기 위해서는 색인이 필요하다.
- 색인
  - 기본 데이터에서 파생된 추가적인 구조이고, 많은 데이터베이스는 색인의 추가와 삭제를 허용한다.
  - 질의 성능에 영향을 주고, 추가적인 구조 유지보수는 쓰기 과정에서 오버헤드가 발생한다.
  - 읽기 질의 속도가 향상되지만, 모든 색인은 쓰기 속도를 떨어뜨린다. 
##### **해시 색인**
- 키-값 저장소는 dictionary 타입과 매우 유사해 보통 해시 맵(해시 테이블)으로 구현한다.
- 키를 데이터 파일의 바이트 오프셋에 매핑해 인메모리 해시 맵을 유지하는 전략이 있다.
  - 바이트 오프셋은 값을 바로 찾을 수 있는 위치다.
  - 새로운 키-값 쌍을 추가할 때마다 데이터의 오프셋을 반영하기 위해 해시 맵도 갱신해야 한다.
  - 값을 조회 하려면 해시 맵을 사용해 데이터 파일에서 오프셋을 찾아 해당 위치를 구하고 값을 읽는다.
  - 램에 모든 키가 저장된다는 조건을 전제로 고성능 읽기, 쓰기를 보장한다.
  - 쓰기가 아주 많지만 고유 키가 많지 않은 작업 즉,각 키의 값이 자주 갱신되는 상황에 매우 적합하다.
  - 파일에 항상 추가만 한다면 결국 디스크 공간이 부족해지므로, 세그먼트로 로그를 나눠 특정 크기에 도달하면 세그먼트 파일을 닫고, 새로운 세그먼트 파일에 이후 쓰기를 수행한다.
  - 중복된 키를 버리는 컴팩션을 수행해 각 키의 최신 갱신 값만 유지하게 한다.
  - 컴팩션을 수행할 때 동시에 여러 세그먼트들을 병합할 수 있다.
  - 각 세그먼트는 키를 파일 오프셋에 매핑한 자체 인메모리 해시 테이블을 갖고, 키의 값을 찾으려면 최신 세그먼트 해시 맵을 먼저 확인한 뒤, 이전 세그먼트 해시 맵을 차례로 확인한다.
- **고려해야할 사항**
  - 파일 형식
  - 레코드 삭제
    - 키와 관련된 값을 삭제하려면 데이터 파일에 특수한 삭제 레코드(툼스톤)를 추가한 뒤, 병합 과정에서 삭제된 키의 이전 값을 무시하게 된다. 
  - 고장 복구
    - 데이터베이스가 재시작되면 인메모리 해시 맵은 손실되므로, 복원해야하는데 전체 세그먼트 파일을 처음부터 끝까지 읽고 각 키에 대한 최신 값의 오프셋을 확인해서 각 세그먼트 해시 맵을 복원할 수 있다.
    - 스냅숏을 디스크로 저장해 복구 속도를 높일 수 있다.
  - 부분적 레코드 쓰기
    - 로그에 레코드를 추가하는 도중에도 죽을 수 있다.
  - 동시성 제어
    - 쓰기를 엄격히 순차적으로 로그에 추가할 때 일반적인 구현 방법은 하나의 쓰기 스레드만 사용하는 것이다.
    - 데이터 파일 세그먼트는 추가 전용이거나 불변이므로 다중 스레드로 동시에 읽기를 할 수 있다.
- 추가 전용 설계
  - 추가와 세그먼트 병합은 순차적인 쓰기 작업이기 때문에 무작위 쓰기보다 훨씬 빠르다.
  - 세그먼트 파일이 추가 전용이나 불변이면 동시성과 고장 복구는 훨씬 간단하다.
  - 오래된 세그먼트 병합은 시간이 지남에 따라 조각화되는 데이터 파일 문제를 피할 수 있다.
- 제한 사항
  - 메모리에 저장해야 하므로 키가 너무 많으면 문제가 된다.
  - 범위 질의에 효율적이지 않다.
##### **SS테이블과 LSM 트리**
- 세그먼트 파일 형식에 키-값 쌍을 키로 정렬하는 형식을 정렬된 문자열 테이블 (Sorted String Table, SSTable)이라고 한다.
- SS테이블의 장점
  - 세그먼트 병합은 병합정렬과 유사한 방식으로 파일이 사용 가능한 메모리보다 크더라도 간단하고 효율적이다.
    - 각 파일의 첫번째 키를 읽고 가장 낮은 키를 출력 파일로 복사한 뒤 이 과정을 반복한다.
    - 동일한 키가 있으면 최근 세그먼트의 값은 유지하고 오래된 세그먼트의 값은 버린다.
  - 파일에서 특정 키를 찾기 위해 더는 메모리에 모든 키의 색인을 유지할 필요가 없다.
    - 일부 키에 대한 오프셋을 알려주는 인메모리 색인이 필요하다.
    - 세그먼트 파일에서 키의 정확한 오프셋을 알지 못한다고 해도, 정렬돼 있으므로 인접한 두 키 사이에 있다는 것을 알 수 있어서 두 키의 오프셋 사이만큼 스캔하면 된다.
    - 읽기 요청은 요청 범위 내에서 여러 키-값 쌍을 스캔해야 하기 때문에 해당 레코드들을 블록으로 그룹화하고 디스크에 쓰기 전에 압축한다. 그러면 희소 인메모리 색인의 각 항목은 압축된 블록의 시작을 가리키고, 디스크 공간을 절약하면서 I/O 대역폭 사용도 줄인다.
- **SS테이블 생성과 유지**
  - 레드 블랙 트리나 AVL 트리 같은 데이터 구조를 이용하면 임의로 키를 삽입하고 정렬된 순서로 해당 키를 다시 읽을 수 있다.
    - 쓰기가 들어오면 인메모리 균형 트리 데이터구조인 멤테이블에 추가한다.
    - 멤테이블이 임곗값보다 커지면 SS테이블 파일로 디스크에 기록한다. 새로운 SS파일은 데이터베이스의 가장 최신 세그먼트가 된다.
    - 읽기 요청을 제공하려면 멤테이블에서 키를 찾고, 디스크 상의 가장 최신 세그먼트 부터 가장 오래된 세그먼트까지 차례로 검색한다.
    - 세그먼트 파일을 병합하거나 컴팩션하는 과정은 백그라운드에서 수행한다.
  - 데이터베이스가 고장나면 멤테이블에 있는 가장 최근 쓰기는 손실되므로, 매번 쓰기를 즉시 추가할 수 있게 분리된 로그를 디스크 상에 유지하고, 멤테이블을 SS테이블로 기록할 때 버린다.
- **SS테이블에서 LSM(Log-Structured Merge-Tree) 트리 만들기**
  - 정렬된 파일 병합과 컴펙션 원리를 기반으로 하는 저장소 엔진을 LSM 저장소 엔진이라 부른다.
  - 전문 색인은 유사한 개념을 기반으로 한다.
    - 단어가 언급된 모든 문서를 찾는다.
    - 이 접근법은 키를 단어로, 값은 단어를 포함한 모든 문서의 ID 목록으로 하는 키-값 구조로 구현한다.
- **성능 최적화**
  - 존재하지 않는 키를 찾을 경우 모든 세그먼트까지 검색해야하므로 최적화하기 위해 블룸 필터를 추가적으로 사용한다.
  - 압축하고 병합하는 순서와 시기를 결정하는 다양한 전략이 있다. 
    - 크기 계층 컴펙션: 상대적으로 새롭고 작은 SS테이블을 상대적으로 오래됐고 큰 SS테이블에 연이어 병합한다.
    - 레벨 컴팩션: 키 범위를 더 작은 SS테이블로 나누고 오래된 데이터는 개별 레벨로 이동하기 때문에 컴펙션을 점진적으로 진행해 디스크 공간을 덜 사용한다.
  - LSM 트리의 기본 개념은 백그라운드에서 연쇄적으로 SS테이블을 지속적으로 병합하는 것이다.
##### B트리
- 대부분의 관계형 데이터베이스와 많은 비관계형 데이터베이스에서 사용하는 가장 널리 사용되는 색인 구조이다.
- 키로 정렬된 키-값 쌍을 유지하기 때문에 키-값 검색과 범위 질의에 효율적이다.
- 4KB 크기(때로는 더 큰)의 고정 크기 블록이나 페이지로 나누고 한 번에 하나의 페이지에 읽기 또는 쓰기를 한다.
- 각 페이지는 주소나 위치를 이용해 식별 가능하고, 이로인해 하나의 페이지가 다른 페이지를 참조할 수 있다.
- 구성
  - 한 페이지는 B 트리의 루트로 지정되고, 페이지는 여러 키와 하위 페이지의 참조를 포함한다.
  - 각 하위 페이지는 키가 계속 이어지는 범위를 담당하고 참조 사이의 키는 해당 범위 경계가 어디인지 나타낸다.
  - 최종적으로 개별 키를 포함하는 페이지에 도달하는데, 이 페이지는 각 키의 값을 포함하거나 값을 찾을 수 있는 페이지의 참조를 포함한다.
  - 한 페이지에서 하위 페이지를 참조하는 수를 분기 계수라고 부른다.
- 키 변경 / 추가
  - 키의 값을 갱신하려면 키를 포함하고 있는 리프 페이지를 검색하고 페이지의 값을 바꾼 다음 페이지를 디스크에 다시 기록한다.
  - 새로운 키를 추가하려면 새로운 키를 포함하는 범위의 페이지를 찾아 해당 페이지에 키와 값을 추가한다.
    - 충분한 여유 공간이 없다면 페이지 하나를 반쯤 채워진 페이지 둘로 나누고 상위 페이지가 새로운 키 범위의 하위 부분들을 알 수 있게 갱신한다.
  - 이 알고리즘은 트리가 균형을 유지하는 것을 보장하고, N개의 키를 가진 B 트리는 깊이가 항상 O(log N)이다.
- **신뢰할 수 있는 B 트리 만들기**
  - 쓰기 동작은 새로운 데이터를 디스크 상의 페이지에 덮어쓴다.
  - 삽입 때문에 페이지가 분할된다면 상위 페이지도 두 하위 페이지의 참조를 갱신해야한다. 하지만, 일부 페이지만 기록하고 데이터베이스가 고장 난다면 색인이 훼손되기 때문에 매우 위험하다 (고아 페이지 발생)
  - 이를 스스로 복구할 수 있게 만드려면 디스크 상에 쓰기 전 로그(write-ahead log, WAL)라고 하는 데이터 구조를 추가해 B 트리를 구현한다.
    - 트리 페이지에 변경된 내용을 적용하기 전에 모든 B 트리의 변경 사항을 기록하는 추가 전용 파일이고, 고장 이후 복구될 때 일관성 있는 상태로 B 트리를 복원하는 데 사용한다.
  - 다중 스레드가 동시에 B 트리에 접근한다면 주의 깊게 동시성 제어를 해야한다.
    - 보통 래치(가벼운 잠금)로 트리의 데이터 구조를 보호한다.
- **B 트리 최적화**
  - 페이지 덮어쓰기와 고장 복구를 위한 WAL 유지 대신 일부 데이터베이스는 쓰기 시 복사 방식을 사용한다.
    - 변경된 페이지는 다른 위치에 기록하고 트리에 상위 페이지의 새로운 버전을 만들어 새로운 위치를 가리키게 한다.
  - 페이지의 키를 축약해 쓰면 공간을 절약할 수 있다.
  - 페이지는 디스크 상 어디에나 위치할 수 있고, 질의가 정렬된 순서로 키 범위의 상당 부분을 스캔해야 한다면 모든 페이지에 대해 디스크 찾기가 필요하다.
    - 많은 B 트리 구현에서 리프 페이지를 디스크 상에 연속된 순서로 나타나게끔 트리를 배치하려 시도한다.
  - 트리에 포인터를 추가한다. (각 리프 페이지가 양쪽 형제 페이지에 대한 참조)
  - 프랙탈 트리같은 변형은 디스크 찾기를 줄이기 위해 로그 구조화 개념을 일부 빌렸다.
##### **B 트리와 LSM 트리 비교**
- LSM 트리는 보통 쓰기에서 더 빠른 반면 B 트리는 읽기에서 더 빠르다.
  - 읽기가 LSM 트리에서 더 느린 이유는 각 컴팩션 단계에 있는 여러 가지 데이터 구조와 SS테이블을 확인해야 하기 때문이다.
- **LSM 트리의 장점**
  - 쓰기 증폭
    - B 트리 색인은 쓰기 전 로그와 트리 페이지에 기록해야하므로 최소 두번 기록해야한다. 해당 페이지 내 몇 바이트만 바뀌어도 한 번에 전체 페이지를 기록해야하는 오버헤드도 있다.
    - SS테이블의 반복된 컴펙션과 병합으로 인해 여러 번 데이터를 다시 쓴다.
    - 쓰기가 많은 애플리케이션에서 성능 병목은 디스크에 쓰는 속도일 수 있고, 이 경우 쓰기 증폭은 성능 비용이다.
    - LSM 트리는 상대적으로 쓰기 증폭이 더 낮고 트리에서 여러 페이지를 덮어쓰는 것이 아니라 순차적으로 컴팩션된 SS테이블 파일을 쓰기 때문에 B 트리보다 쓰기 처리량을 높게 유지할 수 있다.
    - LSM 트리는 압축률이 더 좋아서 B 트리보다 디스크에 더 적은 파일을 생성해 저장소 오버헤드가 낮다.
- **LSM 트리의 단점**
  - 컴팩션 과정이 진행 중인 읽기와 쓰기의 성능에 영향을 준다.
  - 초기 쓰기와 멤테이블을 디스크로 방출하는 작업과 컴펙션 스레드가 디스크 대역폭을 공유해야 한다.
  - 컴펙션이 유입 쓰기 속도를 따라갈 수 없으면 디스크 상에 병합되지 않은 세그먼트 수가 디스크 공간이 부족할 때까지 증가하므로 명시적 모니터링이 필요하다.
  - B 트리는 각 키가 색인의 한 곳에만 정확하게 존재하지만, 로그 구조화 저장소 엔진은 다른 세그먼트에 같은 키의 다중 복사본이 존재할 수 있으므로, 강력한 트랜잭션 시맨틱을 제공하는 데이터베이스에는 B 트리가 적합하다.
##### 기타 색인 구조
- 키-값 색인의 대표적인 예는 관계형 모델의 기본키 색인이다.
- **색인 안에 값 저장하기**
  - 값은 실제 로우(문서, 정점)거나 다른 곳에 저장된 로우를 가리키는 참조다.
    - 후자의 경우 로우가 저장된 곳을 힙 파일이라 하고 특정 순서 없이 데이터를 저장한다.
  - 힙 파일 접근
    - 여러 보조 색인이 존재할 때 데이터 중복을 피할 수 있기 때문에 힙 파일 접근은 일반적인 방식이다.
    - 키를 변경하지 않고 값을 갱신할 때 꽤 효율적이다.
  - 클러스터드 색인 
    - 색인에서 힙 파일로 다시 이동하는 일은 읽기 성능에 불이익이 너무 많기 때문에 색인안에 바로 색인된 로우를 저장한다. (모든 로우 데이터 저장)
  - 커버링 색인
    - 색인 안에 테이블의 칼럼 일부를 저장한다.
- **다중 칼럼 색인**
  - 결합 색인
    - 하나의 칼럼에 다른 칼럼을 추가하는 방식
    - 예를들면 (성, 이름)을 키로 전화번호를 값으로 하는 색인을 제공하는 구식 전화번호부와 유사하다.
    - 순서가 정렬돼 있다.
  - 다차원 색인
    - 한 번에 여러 칼럼에 질의하는 더 일반적인 방법
    - 지리 공간 데이터에 중요하게 사용된다.
- **전문 검색과 퍼지 색인**
  - 유사하거나 애매모호한(fuzzy) 질의에는 다른 기술이 필요하다.
- **모든 것을 메모리에 보관**
  - 디스크는 지속성이 있고 가격이 램보다 저렴하다.
  - 인메모리 데이터베이스는 지속성을 목표로 한다.
    - (배터리 전원 공금 RAM과 같은)특수 하드웨어 사용
    - 디스크에 변경 사항의 로그를 기록
    - 디스크에 주기적인 스냅숏을 기록
    - 다른 장비에 인메모리 상태를 복제
  - 인메모리 데이터 구조를 디스크에 기록하기 위한 형태로 부호화하는 오버헤드를 피할 수 있어 더 빠를수도 있다.
  - 디스크 기반 색인으로 구현하기 어려운 데이터 모델을 제공한다 (예: 레디스의 우선순위 큐와 셋)
  - 안티 캐싱 
    - 메모리가 충분하지 않을 때 가장 최근에 사용하지 않은 데이터를 메모리에서 디스크로 내보내고 나중에 다시 접근할 때 메모리에 적재하는 방식
#### 💡 느낀 점
- 원래 한번 훑어서 읽었었는데, NoSQL 데이터베이스가 쓰기 성능이 왜 좋은지에 대해 제대로 알지 못해서 다시 정리하면서 읽었다. 일부 LSM 트리를 사용하는 데이터베이스가 쓰기 성능이 좋은 이유를 알게 됐다.
- B 트리도 읽으면서 원래 알던 내용과 다른 부분들이 있어서 새로 정리했다. 예를들면, 데이터베이스에서 PK 색인도 힙 파일을 가리키는 주소를 들고 있는줄 알았는데 클러스터드 색인은 모든 로우 데이터를 포함하고 있다는 것이다.
- 각 데이터베이스가 어떤 색인 구조를 사용해서 어떤 식으로 성능을 개선하는지, 어떤 식으로 발전해왔는지 알게돼서 깊게 이해할 수 있었고, 추후에 이런 지식들을 고려하면서 실무를 하게되면 도움이 될 것 같다.
- 소프트웨어는 은탄환은 없고 각 상황에 맞는 트레이드 오프를 고려해야한다는 점을 다시 한번 느꼈다. 
