## 📅 2026-02-19
### 📖 읽은 블로그: [Claude Code Action: 조직 전반의 코드 품질을 지키는 AI 코드 리뷰 플랫폼화](https://techblog.lycorp.co.jp/ko/building-ai-code-review-platform-with-claude-code-action)
#### ✏️ 요약
- 서비스와 리포지터리 수가 빠르게 증가하는 상황에서는 개발 환경 및 품질 기준 설정 시 조직 차원에서 일관적인 기준과 방식을 제공하는 것이 더 좋다.
- 각자 리뷰 기준이나 일관성 부재, 온보딩의 어려움 등의 이유로 GitHub Actions를 기반한 Claude Code의 코드 리뷰를 플랫폼화 했다. 
  - Claude Code Action은 이미 제공되고 있는 오픈소스로, PR을 분석해 코드 리뷰와 개선 사항을 제안할 수 있고, 제안 사항을 GitHub 댓글이나 PR 리뷰 형태로 바로 남길 수 있다.
- 리뷰 기준과 실행 로직은 중앙에서 통제하고 각 서비스 리포지토리는 호출만 하는 구조를 만들어 리뷰 품질의 편차를 줄였다.
- 사용자마다 멘션을 하면서 언급하는 단어가 달랐고 이것을 무엇을과 어떻게로 나눠서 받아들여 사용자의 의도는 유연하게 반영하면서 품질 가드레일을 유지하고 일관된 응답 형식을 확보했다.
#### 💡 느낀 점
- 원래는 전사적인 차원에서 일관적인 개발환경이나 품질 기준 설정을 하는게 좋을거라 생각을 했었는데, 여기서는 서비스와 리포지터리가 빠르게 증가하는 상황에서 좋다고 나와있다.
  - 이 부분에 대해서 다시 생각을 해봤는데 각 서비스나 비즈니스마다 요구사항이 다르니 전체적으론 비슷하겠지만 사용기술이나 인프라가 다를 수 밖에 없고 그것으로 인한 것으로 생각이 든다.
  - 근데 또 한편으로는 각각의 사용 기술이나 인프라별로의 기준점을 확실히 잡아놓으면 전사적으로 일관된 품질을 유지할 수 있지 않을까 싶다.
- ~~@claude를 멘션하면 변경사항을 감지해 댓글로 리뷰 결과를 제공한다고 하는데 이를 자동으로 하지 않으면 모르는 사람도 많을 것 같고~~, 반영한다고 해도 빠르게 성장하는 서비스에서 사람들이 리뷰 결과를 꾸준히 읽고 수정을 할까 하는 의문이 들었다.
  - 뭔가 리뷰 결과를 주는데 바이브코딩을 하기 위한 프롬프트 형식으로 어떤 문제가 있고 어떤식으로 고쳐야하는지 나눠서 PR을 올린 사람은 프롬프트만 긁어서 바이브 코딩만 하면 되는 형식으로 하면 어떨까 생각이 든다.
- 지침을 이용하면 조직 관점에서 AI를 컨트롤하는데 도움이 된다는 것을 배웠다.
- 오랜만에 기술블로그를 읽으니 재밌다.